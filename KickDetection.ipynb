{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "fs,x = wavfile.read(\"Cascada - Everytime We Touch (Official Video).wav\")\n",
    "\n",
    "x = x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "filterFreqLp = 300\n",
    "filterFreqHp = 200\n",
    "\n",
    "soslp = signal.butter(10, filterFreqLp, 'lowpass',fs=fs,output='sos')\n",
    "soshp = signal.butter(10, filterFreqHp, 'highpass',fs=fs,output='sos')\n",
    "# w, h = signal.freqs(b, a)\n",
    "\n",
    "# plt.semilogx(w, 20 * np.log10(abs(h)))\n",
    "# plt.title('Butterworth filter frequency response')\n",
    "# plt.xlabel('Frequency [radians / second]')\n",
    "# plt.ylabel('Amplitude [dB]')\n",
    "# plt.margins(0, 0.1)\n",
    "# plt.grid(which='both', axis='both')\n",
    "# plt.axvline(100, color='green') # cutoff frequency\n",
    "# plt.show()\n",
    "\n",
    "filtered = signal.sosfilt(soslp, x).astype(np.int16)\n",
    "filtered = signal.sosfilt(soshp, filtered).astype(np.int16)\n",
    "\n",
    "wavfile.write(\"outputtest.wav\",fs,filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "# Define the length and overlap of the sliding window\n",
    "window_length_sec = .1\n",
    "window_overlap_sec = 0.05\n",
    "window_length = int(window_length_sec * fs)\n",
    "window_overlap = int(window_overlap_sec * fs)\n",
    "\n",
    "# Calculate the power of the filtered signal using a sliding window approach\n",
    "power = []\n",
    "for i in range(0, len(filtered)-window_length, window_overlap):\n",
    "    window = filtered[i:i+window_length]\n",
    "    power.append(np.sum(window ** 2) / window_length)\n",
    "\n",
    "# Plot the power values as a function of time\n",
    "time = np.arange(len(power)) * (window_length - window_overlap) / float(fs)\n",
    "\n",
    "powpow = np.power(power,2)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=powpow, mode='lines'))\n",
    "fig.update_layout(title='Power of Filtered Signal', xaxis_title='Time (s)', yaxis_title='Power')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matched Filter Experiment: Unsucessfull\n",
    "# fsS,Kick = wavfile.read(\"KickSample.wav\")\n",
    "\n",
    "\n",
    "# print(Kick.shape)\n",
    "\n",
    "kick = filtered[int(45.5*44100):int(45.8*44100)]\n",
    "kick= kick[::-1]\n",
    "\n",
    "\n",
    "correlation = np.convolve(filtered,kick , mode='valid')\n",
    "# correlation = signal.correlate(filtered, Kick[::-1].astype(np.int16), mode='same')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=correlation, mode='lines'))\n",
    "fig.update_layout(title='Power of Filtered Signal', xaxis_title='Time (s)', yaxis_title='Power')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = []\n",
    "\n",
    "\n",
    "ispeak = False\n",
    "\n",
    "threshold = 5_000_000\n",
    "\n",
    "for i,sample in enumerate(powpow):\n",
    "    if sample > threshold and not ispeak:\n",
    "        peak += [i]\n",
    "        ispeak = True\n",
    "    elif sample <= threshold and ispeak:\n",
    "        ispeak = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=powpow, mode='lines'))\n",
    "fig.update_layout(title='Power of Filtered Signal', xaxis_title='Time (s)', yaxis_title='Power')\n",
    "\n",
    "ratio = len(powpow)/len(filtered) #*(len(filtered)/fs)\n",
    "# ratio = ratio*10\n",
    "\n",
    "for i, x_line in enumerate(peak):\n",
    "    x_of_line = time[x_line]\n",
    "    # print(int(x_line*ratio))\n",
    "    # print(x_of_line)\n",
    "    fig.add_vline(x=x_of_line, line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "fps = 30\n",
    "\n",
    "whiteFrame = np.ones((160,320,3)).astype(np.uint8)*255\n",
    "\n",
    "greenFrame = np.zeros_like(whiteFrame)\n",
    "greenFrame[:,:,1] = np.ones_like(whiteFrame[:,:,0])*255\n",
    "\n",
    "out = cv.VideoWriter(\"outputAgain.mp4\", cv.VideoWriter_fourcc(*'mp4v'), fps, (320, 160))\n",
    "\n",
    "peakFrame = [int((time[pe])*fps) for pe in peak]\n",
    "\n",
    "for frameNum in range(len(x)//fs*fps):\n",
    "    # t = frameNum/fps\n",
    "\n",
    "    if frameNum+3 in peakFrame:\n",
    "        out.write(greenFrame)\n",
    "    else:\n",
    "        out.write(whiteFrame)\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!ffmpeg -y -i outputAgain.mp4 -i \"Cascada - Everytime We Touch (Official Video).wav\" -map 0:v:0 -map 1:a:0 -c:a aac -b:a 192k  GreenFlashTest.mp4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
